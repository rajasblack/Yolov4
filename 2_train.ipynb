{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607ffba1-cce5-4d41-ab84-859183a8df59",
   "metadata": {},
   "source": [
    "<h2>Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6aa5e0-46ee-42e6-95b0-a5c9c16d4b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 488915367841552176\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8750787781408777290\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config=ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "from input_log_utils_others.yolov3.dataset import Dataset\n",
    "from input_log_utils_others.yolov3.yolov4 import Create_Yolo, compute_loss\n",
    "from input_log_utils_others.yolov3.utils import load_yolo_weights\n",
    "from input_log_utils_others.yolov3.configs import *\n",
    "from input_log_utils_others.evaluate_mAP import get_mAP\n",
    "\n",
    "if YOLO_TYPE == \"yolov4\":\n",
    "    Darknet_weights = YOLO_V4_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V4_WEIGHTS\n",
    "if YOLO_TYPE == \"yolov3\":\n",
    "    Darknet_weights = YOLO_V3_TINY_WEIGHTS if TRAIN_YOLO_TINY else YOLO_V3_WEIGHTS\n",
    "    \n",
    "if TRAIN_YOLO_TINY: TRAIN_MODEL_NAME += \"_Tiny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81d0274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs []\n"
     ]
    }
   ],
   "source": [
    "global TRAIN_FROM_CHECKPOINT\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f'GPUs {gpus}')\n",
    "if len(gpus)>0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd9c9af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations #:  7\n",
      "annotations #:  2\n"
     ]
    }
   ],
   "source": [
    "trainset = Dataset('train')\n",
    "testset = Dataset('test')\n",
    "steps_per_epoch = len(trainset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = TRAIN_EPOCHS * steps_per_epoch\n",
    "\n",
    "\n",
    "if TRAIN_TRANSFER:\n",
    "    Darknet = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=YOLO_COCO_CLASSES)\n",
    "    load_yolo_weights(Darknet, Darknet_weights)\n",
    "    \n",
    "yolo = Create_Yolo(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19260a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping conv2d_93\n",
      "skipping conv2d_101\n",
      "skipping conv2d_109\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_FROM_CHECKPOINT:\n",
    "    try:\n",
    "        yolo.load_weights(TRAIN_CHECKPOINTS_FOLDER + os.path.sep + TRAIN_MODEL_NAME)\n",
    "    except ValueError:\n",
    "        print(\"Shapes are incompatible, transfering from Darknet weights\")\n",
    "        TRAIN_FROM_CHECKPOINT = False\n",
    "        \n",
    "if TRAIN_TRANSFER and not TRAIN_FROM_CHECKPOINT:\n",
    "    for i, l in enumerate(Darknet.layers):\n",
    "        layer_weights = l.get_weights()\n",
    "        if layer_weights != []:\n",
    "            try:\n",
    "                yolo.layers[i].set_weights(layer_weights)\n",
    "            except:\n",
    "                print(\"skipping\", yolo.layers[i].name)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1909571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo(image_data, training=True)\n",
    "        giou_loss=conf_loss=prob_loss=0\n",
    "        \n",
    "        grid=3 if not TRAIN_YOLO_TINY else 2\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "        gradients = tape.gradient(total_loss, yolo.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, yolo.trainable_variables))\n",
    "        # update learning rate            \n",
    "        global_steps.assign_add(1)\n",
    "        if global_steps < warmup_steps:\n",
    "            lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
    "        else:\n",
    "            lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END) * ((1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * (np.pi))))\n",
    "                \n",
    "        optimizer.lr.assign(lr.numpy())\n",
    "        \n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"lr\", optimizer.lr, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/total_loss\", total_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/giou_loss\", giou_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/conf_loss\", conf_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/prob_loss\", prob_loss, step=global_steps)\n",
    "        writer.flush()\n",
    "    return global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2635b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "def validate_step(image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo(image_data, training=False)\n",
    "        giou_loss = conf_loss = prob_loss = 0\n",
    "        grid=3 if not TRAIN_YOLO_TINY else 2\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "    return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b94758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP_model = Create_Yolo(input_size=YOLO_INPUT_SIZE, CLASSES=TRAIN_CLASSES)\n",
    "best_val_loss = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6037752b-70c1-4a41-a9a7-4a1f0e44947d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 step:    0/2, lr:0.000020, giou_loss:   3.32, conf_loss:1922.09, prob_loss:   0.89, total_loss:1926.30\n",
      "epoch: 0 step:    1/2, lr:0.000030, giou_loss:   2.44, conf_loss:1615.99, prob_loss:   0.70, total_loss:1619.13\n",
      "total_val 1652.3031005859375\n",
      "\n",
      "\n",
      "giou_val_loss:   5.34, conf_val_loss:1645.59, prob_val_loss:   1.37, total_val_loss:1652.30\n",
      "\n",
      "\n",
      "epoch: 1 step:    0/2, lr:0.000040, giou_loss:   2.63, conf_loss:1604.89, prob_loss:   0.70, total_loss:1608.22\n",
      "epoch: 1 step:    1/2, lr:0.000050, giou_loss:   3.23, conf_loss:1601.35, prob_loss:   0.88, total_loss:1605.46\n",
      "total_val 1630.6612548828125\n",
      "\n",
      "\n",
      "giou_val_loss:   5.33, conf_val_loss:1623.96, prob_val_loss:   1.37, total_val_loss:1630.66\n",
      "\n",
      "\n",
      "epoch: 2 step:    0/2, lr:0.000060, giou_loss:   3.18, conf_loss:1586.01, prob_loss:   0.85, total_loss:1590.04\n",
      "epoch: 2 step:    1/2, lr:0.000070, giou_loss:   2.42, conf_loss:1569.38, prob_loss:   0.70, total_loss:1572.50\n",
      "total_val 1596.802490234375\n",
      "\n",
      "\n",
      "giou_val_loss:   5.32, conf_val_loss:1590.12, prob_val_loss:   1.36, total_val_loss:1596.80\n",
      "\n",
      "\n",
      "epoch: 3 step:    0/2, lr:0.000080, giou_loss:   2.92, conf_loss:1551.90, prob_loss:   0.88, total_loss:1555.70\n",
      "epoch: 3 step:    1/2, lr:0.000090, giou_loss:   2.58, conf_loss:1531.79, prob_loss:   0.69, total_loss:1535.06\n",
      "total_val 1550.2669677734375\n",
      "\n",
      "\n",
      "giou_val_loss:   5.30, conf_val_loss:1543.62, prob_val_loss:   1.35, total_val_loss:1550.27\n",
      "\n",
      "\n",
      "epoch: 4 step:    0/2, lr:0.000100, giou_loss:   3.02, conf_loss:1507.98, prob_loss:   0.86, total_loss:1511.86\n",
      "epoch: 4 step:    1/2, lr:0.000100, giou_loss:   2.55, conf_loss:1488.42, prob_loss:   0.68, total_loss:1491.65\n",
      "total_val 1491.8155517578125\n",
      "\n",
      "\n",
      "giou_val_loss:   5.27, conf_val_loss:1485.20, prob_val_loss:   1.35, total_val_loss:1491.82\n",
      "\n",
      "\n",
      "epoch: 5 step:    0/2, lr:0.000099, giou_loss:   2.08, conf_loss:1452.16, prob_loss:   0.68, total_loss:1454.93\n",
      "epoch: 5 step:    1/2, lr:0.000098, giou_loss:   3.51, conf_loss:1421.38, prob_loss:   0.83, total_loss:1425.72\n",
      "total_val 1431.2130126953125\n",
      "\n",
      "\n",
      "giou_val_loss:   5.24, conf_val_loss:1424.64, prob_val_loss:   1.34, total_val_loss:1431.21\n",
      "\n",
      "\n",
      "epoch: 6 step:    0/2, lr:0.000096, giou_loss:   3.16, conf_loss:1408.07, prob_loss:   0.87, total_loss:1412.10\n",
      "epoch: 6 step:    1/2, lr:0.000093, giou_loss:   2.33, conf_loss:1384.47, prob_loss:   0.68, total_loss:1387.49\n",
      "total_val 1374.4559326171875\n",
      "\n",
      "\n",
      "giou_val_loss:   5.21, conf_val_loss:1367.92, prob_val_loss:   1.33, total_val_loss:1374.46\n",
      "\n",
      "\n",
      "epoch: 7 step:    0/2, lr:0.000091, giou_loss:   3.10, conf_loss:1346.56, prob_loss:   0.83, total_loss:1350.49\n",
      "epoch: 7 step:    1/2, lr:0.000087, giou_loss:   2.55, conf_loss:1322.04, prob_loss:   0.66, total_loss:1325.26\n",
      "total_val 1319.71484375\n",
      "\n",
      "\n",
      "giou_val_loss:   5.18, conf_val_loss:1313.21, prob_val_loss:   1.32, total_val_loss:1319.71\n",
      "\n",
      "\n",
      "epoch: 8 step:    0/2, lr:0.000084, giou_loss:   2.52, conf_loss:1296.07, prob_loss:   0.65, total_loss:1299.24\n",
      "epoch: 8 step:    1/2, lr:0.000080, giou_loss:   2.72, conf_loss:1288.42, prob_loss:   0.83, total_loss:1291.97\n",
      "total_val 1268.6380615234375\n",
      "\n",
      "\n",
      "giou_val_loss:   5.15, conf_val_loss:1262.18, prob_val_loss:   1.31, total_val_loss:1268.64\n",
      "\n",
      "\n",
      "Deleting ['.\\\\dataset\\\\8.png', ['418,23,333,44,0'], array([[[ 31,  30,  31],\n",
      "        [  1,   0,   1],\n",
      "        [  2,   1,   2],\n",
      "        ...,\n",
      "        [ 32,  31,  32],\n",
      "        [255, 255, 255],\n",
      "        [254, 253, 254]],\n",
      "\n",
      "       [[ 31,  30,  31],\n",
      "        [  1,   0,   1],\n",
      "        [  2,   1,   2],\n",
      "        ...,\n",
      "        [ 32,  31,  32],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[ 31,  30,  31],\n",
      "        [  1,   0,   1],\n",
      "        [  2,   1,   2],\n",
      "        ...,\n",
      "        [ 31,  30,  31],\n",
      "        [254, 253, 254],\n",
      "        [255, 254, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32,  31,  32],\n",
      "        [  2,   1,   2],\n",
      "        [  1,   0,   1],\n",
      "        ...,\n",
      "        [ 32,  31,  32],\n",
      "        [255, 255, 255],\n",
      "        [255, 254, 255]],\n",
      "\n",
      "       [[ 67,  66,  67],\n",
      "        [ 44,  43,  44],\n",
      "        [ 40,  39,  40],\n",
      "        ...,\n",
      "        [ 66,  65,  66],\n",
      "        [254, 252, 253],\n",
      "        [255, 254, 255]],\n",
      "\n",
      "       [[235, 233, 234],\n",
      "        [232, 231, 232],\n",
      "        [231, 229, 230],\n",
      "        ...,\n",
      "        [233, 232, 233],\n",
      "        [255, 255, 255],\n",
      "        [255, 254, 255]]], dtype=uint8)] annotation line\n",
      "IndexError, something wrong with .\\dataset\\8.png removed this line from annotation file\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "There were problems with dataset, I fixed them, now restart the training process.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(TRAIN_EPOCHS):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image_data, target \u001b[38;5;129;01min\u001b[39;00m trainset:\n\u001b[0;32m      3\u001b[0m         results \u001b[38;5;241m=\u001b[39m train_step(image_data, target)\n\u001b[0;32m      4\u001b[0m         cur_step \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m%\u001b[39msteps_per_epoch\n",
      "File \u001b[1;32m~\\MyDocuments\\Digital Lighthouse\\trash_detection\\input_log_utils_others\\yolov3\\dataset.py:136\u001b[0m, in \u001b[0;36mDataset.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exceptions: \n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere were problems with dataset, I fixed them, now restart the training process.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    138\u001b[0m batch_smaller_target \u001b[38;5;241m=\u001b[39m batch_label_sbbox, batch_sbboxes\n",
      "\u001b[1;31mException\u001b[0m: There were problems with dataset, I fixed them, now restart the training process."
     ]
    }
   ],
   "source": [
    "for epoch in range(TRAIN_EPOCHS):\n",
    "    for image_data, target in trainset:\n",
    "        results = train_step(image_data, target)\n",
    "        cur_step = results[0]%steps_per_epoch\n",
    "        print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\".format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
    "    if len(testset) == 0:\n",
    "        print(\"configure TEST options to validate model\")\n",
    "        yolo.save_weights(os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME))\n",
    "        continue\n",
    "    count, giou_val, conf_val, prob_val, total_val = 0.,0,0,0,0\n",
    "    for image_data, target in testset:\n",
    "        results = validate_step(image_data, target)\n",
    "        count += 1\n",
    "        giou_val += results[0]\n",
    "        conf_val += results[1]\n",
    "        prob_val += results[2]\n",
    "        total_val+= results[3]\n",
    "        print(\"total_val\", total_val)\n",
    "        \n",
    "    with validate_writer.as_default():\n",
    "        tf.summary.scalar(\"validate_loss/total_val\", total_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/giou_val\", giou_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/conf_val\", conf_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/prob_val\", prob_val/count, step=epoch)\n",
    "    validate_writer.flush()\n",
    "    print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\"\n",
    "          .format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
    "        \n",
    "    if TRAIN_SAVE_CHECKPOINT and not TRAIN_SAVE_BEST_ONLY:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME+\"_val_loss_{:7.2f}\".format(total_val/count))\n",
    "        yolo.save_weights(save_directory)\n",
    "    if TRAIN_SAVE_BEST_ONLY and best_val_loss>total_val/count:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "        yolo.save_weights(save_directory)\n",
    "        best_val_loss = total_val/count\n",
    "    if not TRAIN_SAVE_BEST_ONLY and not TRAIN_SAVE_CHECKPOINT:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "        yolo.save_weights(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1575422-8384-48c3-b5ec-34adac3065ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ef88e-629b-43cd-bbea-ed120042f30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f85fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ea357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d824424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
